<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Guorun Wang</title>
  
  <meta name="author" content="Guorun Wang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Guorun Wang</name>
              </p>
              <p>I‚Äôm Guorun. I am an Mres student at Imperial College London, supervised by Professor Lucia Specia. I am working on debias of multimodal models.
                I graduate from Data Science and Big Data technology in the Computer Science department, Tongji University. 
              </p>
              <p style="text-align:center">
                <a href="mailto:caffreygr@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/Guorun-CV.pdf">CV</a> &nbsp/&nbsp
                <a href="data/Guorun-bio.txt">Bio</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?hl=en&user=TF2nhCAAAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/grCaffrey">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/CaffreyR">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/Guorun.jpg"><img style="width:70%;max-width:70%" alt="profile photo" src="images/Guorun.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I‚Äôm interested in Multimodal, NLP, Computer Vision. I also have experience in 3D vision and Efficient NLP.
              </p>
              <p>
                I was a research assistant in Cognitive and Intelligent Computing Lab, Tongji University, working on Multimodal in image caption, 2d classification with Professor 
                <a href="https://see.tongji.edu.cn/info/1285/9804.htm">Yaoru Sun</a>.
              </p>
              <p>
                I was a research assistant in <a href="https://h2lab.cs.washington.edu/">H2lab</a> , 
                University of Washington, working on Parameter-efficient NLP with Dr.<a href="https://awk.ai/"> Qingqing Cao(Postdoc)</a> 
                and Professor <a href="https://homes.cs.washington.edu/~hannaneh/index.html">Hannaneh Hajishirzi</a>.
              </p>
              <p>
                I was a research intern in contex.ai, working on 3d NerFs and understanding with Professor <a href="https://lama.doc.ic.ac.uk/team/lucia">Lucia Specia</a> and Dr. <a href="https://www.imperial.ac.uk/people/sharmanska.v">Viktoriia Sharmanska</a>.
              </p>
              <p>
                I was a research assistant of Professor <a href="https://scholar.google.com.tw/citations?user=a3Kzy2wAAAAJ&hl=zh-TW">Kuo-yi Lin</a>.
                , working on Robustness of human body reconstruction and segmentation method.


            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
				
    
    <tr onmouseout="zipnerf_stop()" onmouseover="zipnerf_start()"  >
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='zipnerf_image'><video  width=100% height=100% muted autoplay loop>
          <!-- <source src="images/zipnerf.mp4" type="video/mp4"> -->
          Your browser does not support the video tag.
          </video></div>
          <!-- <img src='images/LoRA.jpg' width="160"> -->
          <!-- <img src='images/zipnerf.jpg' width="160"> -->
        </div>
        <script type="text/javascript">
          function zipnerf_start() {
            document.getElementById('zipnerf_image').style.opacity = "1";
          }

          function zipnerf_stop() {
            document.getElementById('zipnerf_image').style.opacity = "0";
          }
          zipnerf_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://ieeexplore.ieee.org/abstract/document/10322658">
          <papertitle>Deep Pixel-Wise Textures for Construction Waste Classification</papertitle>
        </a>
        <br>
        Jun YangÔºõ <strong>Guorun Wang</strong>; Yaoru Sun; Lizhi Bai; Bohan Yang
        <!-- <p>Jun Yang</p>,
        <a href="https://bmild.github.io/">Ben Mildenhall</a>,
        <a href="https://scholar.harvard.edu/dorverbin/home">Dor Verbin</a>,
        <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>,
        <a href="https://phogzone.com/">Peter Hedman</a> -->
        <br>
        <em>ieee</em>, 2023
        <br>
        <!-- <a href="http://jonbarron.info/zipnerf">project page</a>
        /
        <a href="https://www.youtube.com/watch?v=xrrhynRzC8k">video</a>
        / -->
        <!-- <a href="https://arxiv.org/abs/2303.14704">arXiv</a> -->
        <p></p>
      </td>

      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2303.14704">
          <papertitle>Task-oriented Memory-efficient Pruning-Adapter</papertitle>
        </a>
        <br>
        <strong>Guorun Wang</strong>; Jun Yang; Yaoru Sun
        <!-- <p>Jun Yang</p>,
        <a href="https://bmild.github.io/">Ben Mildenhall</a>,
        <a href="https://scholar.harvard.edu/dorverbin/home">Dor Verbin</a>,
        <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>,
        <a href="https://phogzone.com/">Peter Hedman</a> -->
        <br>
        <em>arXiv</em>, 2023
        <br>
        <!-- <a href="http://jonbarron.info/zipnerf">project page</a>
        /
        <a href="https://www.youtube.com/watch?v=xrrhynRzC8k">video</a>
        / -->
        <a href="https://arxiv.org/abs/2303.14704">arXiv</a>
        <p></p>
      </td>
    </tr>

    <tr onmouseout="zipnerf_stop()" onmouseover="zipnerf_start()"  >
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='zipnerf_image'><video  width=100% height=100% muted autoplay loop>
          <!-- <source src="images/zipnerf.mp4" type="video/mp4"> -->
          Your browser does not support the video tag.
          </video></div>
          <!-- <img src='images/RGBD-seg.jpg' width="160"> -->
        </div>
        <script type="text/javascript">
          function zipnerf_start() {
            document.getElementById('zipnerf_image').style.opacity = "1";
          }

          function zipnerf_stop() {
            document.getElementById('zipnerf_image').style.opacity = "0";
          }
          zipnerf_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://ieeexplore.ieee.org/document/10185116">
          <papertitle>Pixel Difference Convolutional Network for RGB-D Semantic Segmentation</papertitle>
        </a>
        <br>
        Jun Yang, Lizhi Bai, Yaoru Sun, Chunqi Tian, Maoyu Mao, <strong>Guorun Wang</strong>
        <!-- <p>Jun Yang</p>,
        <a href="https://bmild.github.io/">Ben Mildenhall</a>,
        <a href="https://scholar.harvard.edu/dorverbin/home">Dor Verbin</a>,
        <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>,
        <a href="https://phogzone.com/">Peter Hedman</a> -->
        <br>
        <em>IEEE Transactions on Circuits and Systems for Video Technology</em>, 2023
        <br>
        <!-- <a href="http://jonbarron.info/zipnerf">project page</a>
        /
        <a href="https://www.youtube.com/watch?v=xrrhynRzC8k">video</a>
        / -->
        <a href="https://arxiv.org/abs/2302.11951">arXiv</a>
        <p></p>
        <p>
          RGB-D semantic segmentation can be advanced with convolutional neural networks due to the availability of Depth data. Although objects cannot be easily discriminated by just the 2D appearance, with the local pixel difference and geometric patterns in Depth, they can be well separated in some cases. Considering the fixed grid kernel structure, CNNs are limited to lack the ability to capture detailed, fine-grained information and thus cannot achieve accurate pixel-level semantic segmentation. To solve this problem, we propose a Pixel Difference Convolutional Network (PDCNet) to capture detailed intrinsic patterns by aggregating both intensity and gradient information in the local range for Depth data and global range for RGB data, respectively. Precisely, PDCNet consists of a Depth branch and an RGB branch. For the Depth branch, we propose a Pixel Difference Convolution (PDC) to consider local and detailed geometric information in Depth data via aggregating both intensity and gradient information. For the RGB branch, we contribute a lightweight Cascade Large Kernel (CLK) to extend PDC, namely CPDC, to enjoy global contexts for RGB data and further boost performance. Consequently, both modal data's local and global pixel differences are seamlessly incorporated into PDCNet during the information propagation process. Experiments on two challenging benchmark datasets, i.e., NYUDv2 and SUN RGB-D reveal that our PDCNet achieves state-of-the-art performance for the semantic segmentation task.</p>
      </td>
    </tr>

    <tr onmouseout="zipnerf_stop()" onmouseover="zipnerf_start()"  >
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='zipnerf_image'><video  width=100% height=100% muted autoplay loop>
          <!-- <source src="images/zipnerf.mp4" type="video/mp4"> -->
          Your browser does not support the video tag.
          </video></div>
          <!-- <img src='images/posing.jpg' width="160"> -->
        </div>
        <script type="text/javascript">
          function zipnerf_start() {
            document.getElementById('zipnerf_image').style.opacity = "1";
          }

          function zipnerf_stop() {
            document.getElementById('zipnerf_image').style.opacity = "0";
          }
          zipnerf_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <p>
          <a href="https://ieeexplore.ieee.org/abstract/document/10236832">
            <papertitle>	
              What are You Posing: A gesture description dataset based on coarse-grained semantics</papertitle>
          </a>
          </p>
        <br>
        Luchun Chen, <strong>Guorun Wang</strong>, Yaoru Sun, Rui Pang, Chengzhi Zhang
        <!-- <p>Jun Yang</p>,
        <a href="https://bmild.github.io/">Ben Mildenhall</a>,
        <a href="https://scholar.harvard.edu/dorverbin/home">Dor Verbin</a>,
        <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>,
        <a href="https://phogzone.com/">Peter Hedman</a> -->
        <br>
        <em>ICNLP</em>, 2023
        <br>
        <!-- <a href="http://jonbarron.info/zipnerf">project page</a>
        /
        <a href="https://www.youtube.com/watch?v=xrrhynRzC8k">video</a>
        / -->
        <!-- <p>In press</p> -->
        <!-- <a href="https://www.inderscienceonline.com/doi/abs/10.1504/IJIMS.2022.128640">website</a> -->
        <p></p>
      </td>
    </tr>

    <tr onmouseout="zipnerf_stop()" onmouseover="zipnerf_start()"  >
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='zipnerf_image'><video  width=100% height=100% muted autoplay loop>
          <!-- <source src="images/zipnerf.mp4" type="video/mp4"> -->
          Your browser does not support the video tag.
          </video></div>
          <!-- <img src='images/U2p.jpg' width="160"> -->
        </div>
        <script type="text/javascript">
          function zipnerf_start() {
            document.getElementById('zipnerf_image').style.opacity = "1";
          }

          function zipnerf_stop() {
            document.getElementById('zipnerf_image').style.opacity = "0";
          }
          zipnerf_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://www.inderscienceonline.com/doi/abs/10.1504/IJIMS.2022.128640">
          <papertitle>	
            U2 Net-Plus and background removal-based PIFu-HD: human body reconstruction in complex background</papertitle>
        </a>
        <br>
        <strong>Guorun Wang</strong>, Xudong Liu, Kuo-Yi Lin, Fuhjiun Hwang
        <!-- <p>Jun Yang</p>,
        <a href="https://bmild.github.io/">Ben Mildenhall</a>,
        <a href="https://scholar.harvard.edu/dorverbin/home">Dor Verbin</a>,
        <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>,
        <a href="https://phogzone.com/">Peter Hedman</a> -->
        <br>
        <em>International Journal of Internet Manufacturing and Services</em>, 2022
        <br>
        <!-- <a href="http://jonbarron.info/zipnerf">project page</a>
        /
        <a href="https://www.youtube.com/watch?v=xrrhynRzC8k">video</a>
        / -->
        <a href="https://www.inderscienceonline.com/doi/abs/10.1504/IJIMS.2022.128640">website</a>
        <p></p>
      </td>
    </tr>

    <tr onmouseout="zipnerf_stop()" onmouseover="zipnerf_start()"  >
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='zipnerf_image'><video  width=100% height=100% muted autoplay loop>
          <!-- <source src="images/zipnerf.mp4" type="video/mp4"> -->
          Your browser does not support the video tag.
          </video></div>
          <!-- <img src='images/zipnerf.jpg' width="160"> -->
        </div>
        <script type="text/javascript">
          function zipnerf_start() {
            document.getElementById('zipnerf_image').style.opacity = "1";
          }

          function zipnerf_stop() {
            document.getElementById('zipnerf_image').style.opacity = "0";
          }
          zipnerf_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <p>
          <papertitle>	
            <!-- 2 papers coming soon</papertitle> -->
          </p>
        

				
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Friends who help me a lot!</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
					
          <tr>
            <!-- <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td> -->
            <td width="75%" valign="center">
              <a href="http://yao-lirong.github.io/">Lirong Yao</a>
              <br>
              <a href="http://lzqlearn.com/">Gilgamesh</a>
              
					
					
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Website adapted from <a href="https://github.com/jonbarron/website">Jon Barron</a>, many thanks!!!
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
